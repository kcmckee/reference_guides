{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Logistic Regression in Python #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Killian McKee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "1. [What is Logistic Regression?](#section1)\n",
    "2. [Pros and Cons of Logistic Regression](#section2)\n",
    "3. [When to use Logistic Regression](#section3)\n",
    "4. [Key Parameters](#section4)\n",
    "5. [Walkthrough: Binary Logistic Regression](#section5)\n",
    "6. [Review](#section6) \n",
    "7. [Related Topics](#section7) \n",
    "8. [Sources](#section8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Logistic Regression? ###\n",
    "\n",
    "Logistic regression is a classification algorithm used to predict the probability of some (usually two) categorical variables. In binomial regression, the dependent variable is a binary variable where data is coded as a 1 (success) or a 0 (faiulure, no). When we perform logistic regression on multiple classes we would have additional classes for each dependent variable. Logistic regression models predict the probability Y=1 given X. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='log_vs_linear.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='log_reg.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of Logistic Regression ###\n",
    "\n",
    "#### Pros ###\n",
    "\n",
    "1. Easy to interpret since the output can be displayed by probability\n",
    "2. Can also be used for ranking \n",
    "3. Fast\n",
    "4. Low variance \n",
    "\n",
    "#### Cons ####\n",
    "\n",
    "1. Prone to high bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use Binomial Logistic Regression ###\n",
    "\n",
    "Binomial logistic regression is good at predicting whether something falls into one of two categories (win/lose,pass/fail,sick/ill,etc.) when when the following conditions are met:\n",
    "\n",
    "1. The dependent variable is binary i.e. there are two possible outcomes\n",
    "2. The independent variables should be independent of one another i.e. there is no (or very little) multicollinearity\n",
    "3. Sample sizes are large\n",
    "4. The independent variables are linearly related to the log odds\n",
    "5. Only meaningful variables are included (using a method like PCA or Lasso can help with finding meaningful variables). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Parameters ### \n",
    "\n",
    "The equation for logistic regression is P=(1/(1+e^(b0+b1x)). The key parameters:\n",
    "\n",
    "1. b0 controls how far to the left or right the curve is on a graph \n",
    "2. b1 controls the steepness of the curve (slope)\n",
    "\n",
    "Typically, logistic regression is computed with packages like sci-kit learn, more info on those parameters [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Notes ### \n",
    "\n",
    "Logistic regression works best with large sample sizes. [Cross validation](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f) is a tool to help evaluate the ability of a model to fit to new test data, and is especially valuable when sample sizes are small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression Walkthrough ###\n",
    "\n",
    "Let's walk through a simple example of how we might perform a binary logistic regression to predict what species of iris we are looking at given features like petal length and width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\598386\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "from vega_datasets import data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petalLength</th>\n",
       "      <th>petalWidth</th>\n",
       "      <th>sepalLength</th>\n",
       "      <th>sepalWidth</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petalLength  petalWidth  sepalLength  sepalWidth species\n",
       "0          1.4         0.2          5.1         3.5  setosa\n",
       "1          1.4         0.2          4.9         3.0  setosa\n",
       "2          1.3         0.2          4.7         3.2  setosa\n",
       "3          1.5         0.2          4.6         3.1  setosa\n",
       "4          1.4         0.2          5.0         3.6  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the datasets \n",
    "iris_df=data.iris()\n",
    "\n",
    "#examine the dataset\n",
    "iris_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#since we are interested in the predicting the species, lets see how many unique entries this column contains\n",
    "print(iris_df['species'].nunique())\n",
    "\n",
    "#we are only going to predict two species, so lets drop the virginica species from our dataframe\n",
    "iris_df=iris_df[iris_df['species']!='virginica']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   petalLength  petalWidth  sepalLength  sepalWidth\n",
      "0          1.4         0.2          5.1         3.5\n",
      "1          1.4         0.2          4.9         3.0\n",
      "2          1.3         0.2          4.7         3.2\n",
      "3          1.5         0.2          4.6         3.1\n",
      "4          1.4         0.2          5.0         3.6\n",
      "(100, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    setosa\n",
       "1    setosa\n",
       "2    setosa\n",
       "3    setosa\n",
       "4    setosa\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we select our x data so that we can perform a train test split\n",
    "#this will be everything species column, which is our dependent variable \n",
    "\n",
    "X=iris_df.iloc[:,:-1]\n",
    "print(X.head())\n",
    "print(X.shape)\n",
    "\n",
    "#our y data will be our dependent variable (species)\n",
    "\n",
    "y=iris_df.iloc[:,-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now we split up our training and testing data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the training data \n",
    "#we have 75 rows with 4 columns (petal length width, sepal length, width, etc.)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=18, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time to fit our regression model! \n",
    "#use this method when cross validating is less of a concern\n",
    "classifier = LogisticRegression(random_state=18)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we fit a logistic regression model and apply cross validation, which would be the preferred method when computational\n",
    "#constraints are not high or the model is small\n",
    "#we see the model is still getting 100% accuracy, likely because of the clean sample data \n",
    "\n",
    "classifier= LogisticRegressionCV(cv=5, random_state=0).fit(X, y)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "#lets call a confusion matrix to see how we did\n",
    "#we can see the model was 100% accurate on our test data, which should typically raise suspicion but in this case is ok\n",
    "#because the data is very clean. \n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you're looking for information on confusion matrices look [here](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        13\n",
      " versicolor       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review ###\n",
    "\n",
    "We learned that logistic regression is a useful tool for solving classification problems when the independent variables are linearly related to the log odds and the independent variables are meaningful (more criteria for binomial regressions). Next, we did a basic walkthrough of a binomial logistic regression and performed cross validation to evaluate how our regressor handled new data. Lastly, we created a classification report to view the accuracy of our logit model on withheld test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Topics ### \n",
    "\n",
    "1. [Multinomial Logistic Regression](https://en.wikipedia.org/wiki/Multinomial_logistic_regression)\n",
    "2. [The Math Behind Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources ### \n",
    "\n",
    "1. https://www.saedsayad.com/logistic_regression.htm\n",
    "2. https://datascienceplus.com/building-a-logistic-regression-in-python-step-by-step/\n",
    "3. http://aritter.github.io/courses/5525_slides/logistic_regression.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
